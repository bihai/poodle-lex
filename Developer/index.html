<html>
    <head>
        <title>Poodle-Lex Developer Documentation</title>
        <link rel="stylesheet" href="style.css" />
    </head>
    <body>
        <h1>Poodle-Lex Developer Documentation</h1>
        <p>This documentation is meant to provide an introduction into 
        understanding the Poodle-Lex source code for anyone who wishes to
        develop for, borrow from, or simply learn about the application.</p>
        
        <h2>Getting Started</h2>
        <p>Poodle-Lex is written in Python. To run Poodle-Lex from source, 
        install the following dependencies</p>
        <ul>
            <li><a href="https://www.python.org/">Python 2</a>, version 2.7 or higher</a></li>
            <li><a href="https://pypi.python.org/pypi/blist/">blist</a></li>
            <li><a href="http://git-scm.com/downloads">Git</a></li>
        </ul>
        
        <p>Once all dependencies have been acquired, clone the Poodle-Lex
        repository using git:</p>
        <code>git clone https://github.com/parkertomatoes/poodle-lex.git</code>
        <p>Create a folder to hold the source and navigate to it in a command 
        prompt or terminal. Then run __main__.py using Python:</p>
        <code>mkdir Output
python __main__.py Example/SimpleLexer/SimpleLexer.rules Output</code>
        
        <h2>Overview</h2>
        <p>Poodle-Lex consumes a rules file containing regular expressions and
        produces source code which can accept strings and match them to 
        rules. It does this though a series of steps which are a well 
        known part of compter science.<p>
        <ol>
            <li><a href="#ParseRulesSection">Parse</a> a rules file into a list of name and regular expression strings</li>
            <li><a href="#ParseRegexSection">Parse</a> each regular expression into a structure</li>
            <li><a href="#RegexToNFASection">Convert</a> each regular expression into an NFA using 
            <a href="http://en.wikipedia.org/wiki/Thompson's_construction_algorithm">Thompson Construction</a></li>
            <li><a href="#NFAToDFASection">Convert</a> each NFA into a DFA using 
            <a href="http://en.wikipedia.org/wiki/Powerset_construction">powerset construction</a></li>
            <li><a href="#MinimizeDFASection">Minimize</a> the DFA</li>
            <li><a href="#EmitCodeSection">Emit</a> the DFA as source code</li>
        </ol>
        
        <p>This document only brushes over general theory about automata and 
        regular languages See the resources below for more information:</p>
        <ul>
            <li><a href="http://en.wikipedia.org/wiki/Automata_theory">Wikipedia</a></li>
            <li>MIT OpenCourseware: Aaronson, Scott. 6.045J 
            Automata, Computability, and Complexity, Spring 2011. (MIT 
            OpenCourseWare: Massachusetts Institute of Technology), 
            <a href="http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-045j-automata-computability-and-complexity-spring-2011 (Accessed 29 Mar, 2014). License: Creative Commons BY-NC-SA">http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-045j-automata-computability-and-complexity-spring-2011</a>. 
            License: Creative Commons BY-NC-SA</a></li>
            <li><a href="https://www.google.com/search?q=nondeterministic+finite+automata">Google search</a> which brings up tons of university slides.</li>
        </ul>
        
        <a name="ParseRulesSection" />
        <h2>Parsing the rules file</h2>
        <p><em>Source file: <a href="../Source/Generator.LexicalAnalyzerParser-module.html">Generator/LexicalAnalyzerParser.py</a></em></p>
        <p>Before creating a lexical analyzer, Poodle-Lex parses a rules file 
        to obtain a list of rules and variables.</p>
        <p>The parser is a hand-made recursive descent parser which uses 
        the output of
        <a href"http://docs.python.org/library/re.html">re.finditer</a>
        as a lexical analyzer</a>. The parser is an iterator generator
        which yields both rules and variable definitions.</p>
        
        <p>The parser is only accessed through the static method
        <a href="../Source/Generator.LexicalAnalyzer.LexicalAnalyzer-class.html#parse">LexicalAnalyzer.parse()</a>,
        which takes in a filename and outputs a
        <a href="../Source/Generator.LexicalAnalyzer.LexicalAnalyzer-class.html">LexicalAnalyzer()</a> structure.</a>        
        <p>LexicalAnalyzer contains rules, variable definitions, and methods 
        to convert the lexical analyzer to its final form before emitting.</p>
        
        <h3>Rules File Grammar</h3>
        <ul>
            <li><strong>body:</strong> line+;</li>
            <li><strong>line:</strong> ws (comment | variable_definition | rule_definition)? ws "\r"? "\n";</li>
            <li><strong>comment:</strong> "#" [^\n]+;</li>
            <li><strong>variable_definition:</strong> "let" ws identifier ws "=" ws rule_expression;</li>
            <li><strong>rule_definition:</strong> (identifier ws)? identifier ws ":" ws rule_expression;</li>
            <li><strong>rule_expression:</strong> "i"? string (ws "+" wsnl string)*;</li>
            <li><strong>string:</strong> double_quote_string | single_quote_string;
            <li><strong>double_quoted_string:</strong> '"' ([^'"'] | '""')* '"';</li>
            <li><strong>single_quoted_string:</strong> "'" ([^"'"] | "''")* "'";</li>
            <li><strong>ws:</strong> [ \t]*;</li>
            <li><strong>wsnl:</strong> [ \t\r\n]*;</li>
        </ul>

        <a name="ParseRegexSection" />
        <h2>Parsing the regular expressions</h2>
        <p><em>Source files:</em></p>
        <ul>
            <li><em>Parser: <a href="../Source/Generator.RegexParser-module.html">Generator/RegexParser.py</a></em></li>
            <li><em>Structure: <a href="../Source/Generator.Regex-module.html">Generator/Regex.py</a></em></li>
        </ul>
        <p>Once the rules file is parsed into a list of rules and variable 
        definitions, each regular expression is represented with a string.
        To be usable, the string is parsed into an 
        <a href="http://en.wikipedia.org/wiki/Visitor_pattern">visitable</a> 
        abstract tree representing the reglar expression. Each object in 
        the tree is either a set of characters or a relationship between
        other tree elements:</p>
        <ul>
            <li><a href="../Source/Generator.Regex.Literal-class.html">Literal:</a> the primitive tree element, matches a single character (a, [ab])</li>
            <li><a href="../Source/Generator.Regex.Alternation-class.html">Alternation:</a> matches one of several tree elements (a|b)</li>
            <li><a href="../Source/Generator.Regex.Concatenation-class.html">Concatenation:</a> matches a sequence of tree elements (ab)</li>
            <li><a href="../Source/Generator.Regex.Repetition-class.html">Repetition:</a> matches a single tree element repeated a number of times (a*, a+, a?, a{1, 2})</li>
            <li><a href="../Source/Generator.Regex.Variable-class.html">Variable instance:</a> Placeholder to be substituted with another tree element ({a})</li>
        </ul>
       
        <p>For example, "cat+|dog" is parsed into the following structure:</p>
        <div class="indent">Alternation(
            <div class="indent">Repetition(
                <div class="indent">Concatenation(
                    <div class="indent">Literal("c"),</div>
                    <div class="indent">Literal("a"),</div>
                    <div class="indent">Literal("t")</div>
                ),</div>
            1, inf),</div>
            <div class="indent">Concatenation(
                <div class="indent">Literal("d"),</div>
                <div class="indent">Literal("o"),</div>
                <div class="indent">Literal("g")</div>
            )</div>
        )</div>
        
        <p>Like the rules file parser, the regular expression parser is 
        a hand-made recursive descent parser. It takes in individual 
        characters as its terminals. Because of this, a dedicated lexical is 
        not necessary.</p>
        
        <h3> Regular Expression Grammar</h3>
        <ul>
            <li><strong>pattern:</strong> concatenation ( "|" concatenation )+</li>
            <li><strong>concatenation:</strong> repetition+;</li>
            <li><strong>repetition:</strong> character ("+" | "*" | "?" | "{" integer "," integer "}")?;</li>
            <li><strong>character:</strong> literal | "(" pattern ")" | variable | character_class;</li>
            <li><strong>literal:</strong> escape_sequence | [^"\\"];</li>
            <li><strong>escape_sequence:</strong> "\\" ([^Uux] | hex_ascii | hex_ucs2 | hex_unicode);</li>
            <li><strong>hex_ascii:</strong> "x" [0-9a-fA-F]{2,2};</li>
            <li><strong>hex_ucs2:</strong> "u" [0-9a-fA-F]{4,4};</li>
            <li><strong>hex_unicode:</strong> "U" [0-9a-fA-F][6,6];</li>
            <li><strong>variable:</strong> "{" identifier "}";</li>
            <li><strong>identifier:</strong> [a-zA-Z][a-zA-Z0-9_]*</li>
            <li><strong>character_class:</strong> "[" character_class_item+ "]";</li>
            <li><strong>character_class_item:</strong> named_character_class | literal ("-" literal)?;</li>
            <li><strong>named_character_class:</strong> "[:" [a-z]{5,5} ":]";</li>
        </ul>
        
        <a name="RegexToNFASection" />
        <h2>Converting the regular expressions to an NFA</h2>
        <p><em>Source files:</em></p>
        <ul>
            <li><em>NFA Structure: <a href="../Source/Generator._NonDeterministicFiniteAutomata-module.html">Generator/_NonDeterministicFiniteAutomata.py</em></a></li>
            <li><em>Conversion: <a href="../Source/Generator.NonDeterministicFiniteAutomataBuilder-module.html">Generator/NonDeterministicFiniteAutomataBuilder.py</em></a></li>
        </ul>
        <p>Before the regular expression is converted to code, it must be 
        converted into a non-deterministic finite automaton (NFA). An NFA is a 
        state machine which has one start state and one end state, and an be 
        in more than one state at a time. NFA's are difficult to simulate on a 
        CPU, but easy to generate from a regular expression.</p>
        <p>Poodle-lex converts regular expressions to NFAs using the Thompson 
        Construction algorithm, sometimes called subset construction. General 
        information about NFAs and Thompson construction are beyond the scope 
        of this document, but there is abundent information about these 
        topics. 
        
        <h3>The NFA data structure</h3>
        <p>NFAs are stored in Poodle-Lex using the 
        NonDeterministicFiniteAutomata 
        class. This class does little except to point to
        the start and end states of the class. The states, each represented 
        by a 
        NonDeterministicState 
        object, define most of the structure of the NFA.</p>
        
        <p>Each state contains four main components:</p>
        <ul>
            <li><strong>epsilon_edges</strong>: A set of 
                NonDeterministicState 
                objects connected by epsilon edges.</li>
            <li><strong>edges</strong>: Represents transitions to other 
                states. edges is a dict, with the keys being a 
                NonDeterministicState object representing the destination of 
                the edges, and the values being a range of values which cause
                a transition to that other state. The range of values is
                represented by a 
                ConverageSet
                object.</li>
            <li><strong>ids</strong>: Contains a set of possible
                rules which can be eventually matched if in this
                state.</li>
            <li><strong>final_ids</strong>: If this state is a
                final state, contains a set of names of rules which are 
                current matched in this state.</li>
        </ul>
        
        <p>For example, consider the following NFA, which matches 'a' or 'aaa':</p>
        <img src="simple-nfa.png" alt="A simple NFA matching 'a' or 'aaa'" />
        <p>This state machine can be created with the following Python code:</p>
        <code># Value of an edge 'a'
a = CoverageSet([(ord('a'), ord('a'))])
        
# State machine and states
state_machine = Automata.NonDeterministicFiniteAutomata()
s1 = Automata.NonDeterministicState()
s2 = Automata.NonDeterministicState()

# Edges
state_machine.start_state.edges[s1] = a
s1.edges[s2] = a
s1.epsilon_edges.add(state_machine.end_state)
s2.edges[state_machine.end_state] = a
        </code>
        
        <h3>Building the NFA from a regular expression structure</h3>
        <p>Thompson Construction is relatively simple. Once a regular 
        expression is broken down into parts (Alternation, Concatenation, 
        etc), each part can be substituted for an equivalent NFA 
        representation. Different representations are chained together
        with epsilon edges.</p>
        <p>To recursively iterate though the regular expression tree
        structure, Poodle-Lex makes use of a
        <a href="http://en.wikipedia.org/wiki/Visitor_pattern">visitor</a> 
        class to act differently on different types of tree elements, the 
        <a href="../Source/Generator._NonDeterministicFiniteAutomata.NonDeterministicFiniteAutomata-class.html">NonDeterministicFiniteAutomata</a>
        class. This class visits the root of the tree, and first
        visits the children of each node, pushing their equivelent NFA onto 
        a stack. Then the children are popped off the stack and merged
        using static helper methods such as 
        <a href ="../Source/Generator._NonDeterministicFiniteAutomata.NonDeterministicFiniteAutomata-class.html#alternate">Alternate</a>
        and 
        <a href ="../Source/Generator._NonDeterministicFiniteAutomata.NonDeterministicFiniteAutomata-class.html#concatenate">Concatenate</a>. Because visiting each child means the
        entire tree is visited, visiting the root of the tree results in an
        NFA equivalent to the entire regular expression.</p>
        
        <h3>Combining several individual rules into one NFA</h3>
        <p>Multiple regular expression "rules" can be merged into a single NFA
        by simply alternating the individual NFAs for each rule, which is the 
        equivalent of the regular expression "{rule1}|{rule2}|{rule3}".</p>
        <p>To keep track of which rule is which, the <strong>ids</strong> 
        property of each NFA state is tagged with the name of the rule that 
        the state originated from. The <strong>final_ids</strong> property for 
        the final state is tagged with a rule name as well. When the states 
        are combined later, the tags identify which rules are matched when the 
        state machine is in the combined state.</p>
        
        <a name="NFAToDFASection" />
        <h2>Converting the NFA to a DFA</h2>
        <p><em>Source files:</em></p>
        <ul>
            <li><em>NFA to DFA: <a href="../Source/Generator.DeterministicFiniteAutomataBuilder-module.html">Generator/DeterministicFiniteAutomataBuilder.py</a></em></li>
            <li><em>DFA Structure: <a href="../Source/Generator._DeterministicFiniteAutomata-module.html">Generator/_DeterministicFiniteAutomata.py</a></em></li>
        </ul>
        
        <p>NFAs are not ideal for single-threaded CPU execution (though they 
        are highly-parallel processors such as FPGAs), so Poodle-Lex next
        converts the NFA to a 
        <a href="http://en.wikipedia.org/wiki/Deterministic_finite_automata">deterministic finite automata (DFA)</a>
        A DFA is a state machine which can only be in one state at a time,
        and state transitions only occur due to input characters. In 
        Poodle-Lex, they are represented by the 
        <a href="../Source/Generator._DeterministicFiniteAutomata.DeterministicFiniteAutomata-class.html">DeterministicFiniteAutomata</a> class.</p>
        
        <h3>The DFA data structure</h3>
        <p>The DeterministicFiniteAutomata class is equivalent to the 
        NondeterministicFiniteAutomata class, except that there are no 
        epsilon edges, and no unified end state. The class exists to 
        point to a single 
        <a href="../Source/Generator._DeterministicFiniteAutomata.DeterministicState-class.html">DeterministicState</a>
        object representing the start state. The DeterministicState object 
        contains the same <strong>edges</strong>, <strong>ids</strong>,
        and <strong>final_ids</strong> fields as the NFA data structure.
        The only difference is that edges now points to other
        DeterministicState objects instead of NondeterministicState 
        objects.</p>
        <p>A populated <strong>final_ids</strong> property indicates that a 
        given state is a final state. For instace, consider the following DFA. 
        The DFA matches 'a' or 'aaa', like the NFA from the previous 
        section. States with double outlines are final states.</p>
        <img src="simple-dfa.png" alt="A simple DFA matching 'a' or 'aaa'" />
        <p>This state machine can be created with the following Python code:</p>
        <code># Value of an edge 'a'
a = CoverageSet([(ord('a'), ord('a'))])
        
# State machine and states
state_machine = Automata.DeterministicFiniteAutomata()
s1 = Automata.DeterministicState()
s2 = Automata.DeterministicState()
s3 = Automata.DeterministicState()
s1.final_ids.add('rule')
s3.final_ids.add('rule')

# Edges
state_machine.start_state.edges[s1] = a
s1.edges[s2] = a
s2.edges[s3] = a</code>
        
        <h3>Converting an NFA to a DFA</h3>
        <p>An NFA can exist in multiple states at once. To convert an NFA to a 
        DFA, every combination of multiple NFA states the state machine can be
        in at one time must be found. Each combination of simultaneous states
        is then considered one DFA state. This process is called 
        <a href="http://en.wikipedia.org/wiki/Powerset_construction">powerset construction</a> and is described in more detail
        in other widely available resources.</p>
        <p>Poodle-Lex performs this process by completely traversing the NFA,
        and finding the <strong>epsilon closure</strong> of each state the 
        traverser is in. The epsilon closure of a set of NFA states is a set 
        of all the states given, plus all the states reachable 
        through epsilon edges. It finds all the simultaneous states a 
        traverser can be in. Poodle-Lex uses a separate recursive crawler, 
        the <a href="../Source/Generator.DeterministicFiniteAutomataBuilder.EpsilonClosureCrawler-class.html">EpsilonClosureCrawler</a> class, to 
        find the epsilon closure for a set of states.</p>
        <p>The 
        <a href="../Source/Generator.DeterministicFiniteAutomataBuilder.DeterministicFiniteAutomataBuilder-class.html">DeterministicFiniteAutomataBuilder</a>
        class is responsible for converting the NFA to a DFA. It starts by 
        taking the epsilon closure of the start state of the NFA. Then, a DFA 
        is created, and its start state is mapped to the epsilon closure.</p>
        <p>The builder then traverses the NFA. For every new combination of 
        states the builder is in, it expands the set to include the epsilon 
        closure of those states. Then it creates a DFA state to represent that
        combination of states. This process gradually builds up the DFA as it 
        traverses the NFA. When the NFA is completely traversed, and no new 
        combinations of NFA states are found, the DFA is an equivalent state 
        machine to the NFA.</p>
        <p>When a DFA state is created from a set of NFA states, the values of 
        <strong>ids</strong> and <strong>final_ids</strong> for the DFA state
        is the union of all the values of <strong>ids</strong> and 
        <strong>final_ids</strong> of the NFA. This allows a DFA state to be
        matched to one or more rules.</p>
        
        <a name="MinimizeDFASection" />
        <h2>Minimizing the DFA</h2>
        <p><em>Source files:</em></p>
        <ul>
            <li><em>Hopcroft: <a href="../Source/Generator.HopcroftDFAMinimizer-module.html">Generator/HopcroftDFAMinimizer.py</a></em></li>
            <li><em>Polynomial: <a href="../Source/Generator.NaiveDFAMinimizer-module.html">Generator/NaiveDFAMinimizer.py</a></em></li>
        </ul>
        
        <p>When a DFA is created from an NFA, there is enough information to 
        create equivalent source code. But the source code may be inefficient. 
        Before emitting source code, Poodle-Lex (and most similar programs) 
        minimize the state machine to reduce the number of states.</p>
        <p>A popular algorithm for minimizing a state machine is 
        <a href="http://en.wikipedia.org/wiki/DFA_minimization#Hopcroft.27s_algorithm">Hopcroft's Algorithm</a>,
        which costs 
        <a href="http://en.wikipedia.org/wiki/Big_O_notation">n*s*O(n)^2</a> 
        iterations, where n is the number of states and s is the size of the
        input alphabet. Poodle-Lex, by default, minimizes the state machine 
        using an implementation of this algorithm.</p>
        <p>Poodle-Lex also includes a basic O(n^2) algorithm which compares
        each state to each state and merges them if they are equivalent. This 
        implementation is several times slower, however, and only exists 
        for demonstrative purposes and for internal unit testing.</p>
        
        <a name="EmitCodeSection" />
        <h2>Generating source code from the DFA</h2>
        <p><em>Source files:</em></p>
        <ul>
            <li><em>Plugin loader: <a href="../Source/Generator.LanguagePlugins-module.html">Generator/LanguagePlugins.py</a></em></li>
            <li><em>Plugin template: <a href="../Source/Generator.Emitter.PluginTemplate-module.html">Generator/Emitter/PluginTemplate.py</a></em></li>
        </ul>

        <p>DFA state machines can be easily represented in most programming
        languages. Consider the state machine from previous sections:</p>
        <img src="simple-dfa.png" alt="A simple NFA matching 'a' or 'aaa'" />
        <p>This state machine can be represented with the following 
        (badly written and not recommended) code:</p>
        <code>int accept(FILE* f) {
    start: if (fgetc(f) == 'a') goto s1;
           else return FALSE;
    s1:    if (fgetc(f) == 'a') goto s2;
           else return TRUE;
    s2:    if (fgetc(f) == 'a') goto s3;
           else return FALSE;
    s3:    return TRUE;
}</code>
        <p>The last step Poodle-Lex takes it to generate source code 
        equivalent to the DFA. In order to maintain flexibility, 
        Poodle-Lex relies on emitter plugins written in Python.</p>
        
        <h3>Plug-ins Overview</h3>
        <p>Emitter plugins are defined in 
        <strong>Plugins/Plugins.json</strong>. The json file contains an 
        object with 3 elements:</p>
        <ul>
            <li><strong>Version</strong> <em>(number)</em>: Version of the file format</li>
            <li><strong>Default</strong> <em>(string)</em>: id of the default </li>
            <li><strong>Plugins</strong> <em>(object)</em>: Map of ids to plugins</li>
        </ul>
        <p>The <strong>Plugins</strong> object contains string attributes, 
        each which identifies a plugin. The value of each attribute is an
        object containing 3 pieces of data</p>
        <ul>
            <li><strong>Description</strong> <em>(string)</em>: Description of the plugin</li>
            <li><strong>Source</strong> <em>(string)</em>: Relative path from executable to plugin code</li>
            <li><strong>Files</strong> <em>(string)</em>: Relative path from executable to files made available to plugins such as templates.</li>
        </ul>
        <p>An example of a plug-in file is below:</p>
        <code>{
    "Version": 1,
    "Default": "freebasic",
    "Plugins": {
        "freebasic": {
            "Description": "FreeBasic programming language using proprietary Unicode streams",
            "Source": "Plugins/FreeBasic/FreeBasic.py",
            "Files": "Plugins/FreeBasic/Template"
        },
        "c-ascii": {
            "Description": "C programming language using stdio streams",
            "Source": "Plugins/C-Ascii/C-Ascii.py",
            "Files": "Plugins/C-Ascii/Template"
        }
    }
}</code>
        <p>Plug-ins are loaded at run-time with the
        <a href="https://docs.python.org/2/library/imp.html">imp</a> 
        module, into the Generator.Emitter namespace. After the minimized DFA 
        of the lexical analyzer is generator, the lexical analyzer is passed 
        to the plugin which generates and emits the source code to the output 
        directory.</p>
        
        <h3>The Plug-In Interface</h3>
        <p>The plugin should contain a single function, 
        <strong>create_emitter</strong>, which takes in 3 arguments:</p>
        <ol>
            <li>A <a href="../Source/Generator.LexicalAnalyzer.LexicalAnalyzer-class.html">LexicalAnalyzer</a> object, which contains the DFA of the lexical analyzer</li>
            <li>A string containing the output directory</li>
            <li>A string with the path to the plug-in files specified in PlugIns.json</li>
        </ol>
        <p>The output file should return an object which has a type that is a
        sub-class of
        <a href="../Source/Generator.Emitter.PluginTemplate.PluginTemplate-class.html">Generator.Emitter.PluginTemplate.PluginTemplate</a>.</p>
        <p>The <strong>PluginTemplate</strong> interface has 3 methods that 
        need to be implemented:</p>
        <ul>
            <li><strong>emit</strong>() - Generates code when called. Emits no value</li>
            <li><strong>get_output_directories</strong>() - Return a list of strings, each of a path relative to the output directory for Poodle-Lex to create.</li>
            <li><strong>get_files_to_copy</strong>() - Return a list of strings, each of a file relative to the plugin folder for Poodle-Lex to copy to the output directory</li>
        </ul>
        
        <h3>Utility Classes</h3>
        <p>There are two modules in the Generator.Emitter namespace that are 
        useful for code generation,
        <a href="../Source/Generator.Emitter.FileTemplate-module.html#FileTemplate">FileTemplate</a> 
        and
        <a href="../Source/Generator.Emitter.EmitCode.CodeEmitter-class.html">EmitCode.CodeEmitter</a>
        </p>
        
        <p><strong>FileTemplate</strong>(in_file, out_file) is an iterator 
        generator that takes in an input template file name and an output
        file name. For each variable indicated by a dollar sign in front
        of a variable name (such as "$NAME"), it yields a tuple with 3 
        elements:</p>
        <ol>
            <li>A file stream to write the substituted text</li>
            <li>A string containing the name of the variable to replace</li>
            <li>If the variable is at the start of a line, the number of spaces preceding the variable. Otherwise, None</li>
        </ol>
        <p>For each variable yielded, the user must write what the variable 
        is replaced with to the yielded stream. After iterating through
        the output of FileTemplate(), the output file will be created
        and closed.</p>
        
        <p><strong>CodeEmitter</strong> is a class which decorates a stream
        with methods for creating indented lines often used in programming.
        The constructor takes in a stream, and methods include:</p>
        <ul>
            <li><strong>line</strong>(<em>text</em>) - Write an indented line</li>
            <li><strong>indent</strong>() - Increase the indent by four spaces</li>
            <li><strong>dedent</strong>() - Decreate the indent by four spaces</li>
            <li><strong>open_line</strong>() - Start a new line and write indentation</li>
            <li><strong>write</strong>(<em>text</em>) - Write text without starting a new line</li>
            <li><strong>close_line</strong>() - End the current line and write a new-line</li>
        </ul>
        
        <h3>Navigating the LexicalAnalyzer Object</h3>
        <p>A 
        <a href="../Source/Generator.LexicalAnalyzer.LexicalAnalyzer-class.html">LexicalAnalyzer</a>
        is passed to the language plug-in when creating an emitter object. 
        This class has several methods that can be found in the source 
        documentation, but only two of real interest.</p>
        <ul>
            <li><strong>get_min_dfa</strong>() - Returns a minimized DFA of the lexical analyzer</li>
            <li><strong>rules</strong> - Instance variable, a list of <a href="">Rule</a> objects in order of priority.</li>
        </ul>
        <p>To iterate through the states of the lexical analyzer, one can 
        simply iterate through the output of get_min_dfa(), like so</p>
        <code>for state in lexical_analyzer.get_min_dfa():
    print state.ids</code>
    
        <p>The <strong>Rule</strong> object has an <strong>action</strong>
        attribute which contains the action associated with the rules. If a
        state has matches multiple rules, the order of the Rule objects in 
        the <strong>rules</strong> instance variable can be used to select
        a final match.</p>
    </body>
</html>