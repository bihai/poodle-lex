Poodle-Lex is a lexical analyzer generator, similar to lex and its variants. 
It produces source code which scans an input stream and outputs a stream of 
word units. Features include Unicode support and a platform for supporting 
arbitrary programming languages through plugins.

Usage: Poodle-Lex RULES_FILE OUTPUT_DIR [Optional arguments]

Required arguments:
RULES_FILE: A file containing token names and pattern definitions
OUTPUT_DIR: An existing directory to which the state machine code is written.

Optional arguments:
-n DOT_FILE,  --print-nfa DOT_FILE - Print a GraphViz(.dot) file with the lexical analyzer's NFA representation
-d DOT_FILE,  --print-dfa DOT_FILE - Print a GraphViz(.dot) file with the lexical analyzer's DFA representation
-m DOT_FILE,  --print-min-dfa DOT_FILE - Print a GraphViz(.dot) file with the lexical analyzer's minimized DFA representation.
-e ENCODING,  --encoding ENCODING - Encoding of the input file. ENCODING must be an encoding codec name supported by Python.
-l LANGUAGE,  --language LANGUAGE - Output emitter language.
-i ALGORITHM, --minimizer ALGORITHM - Algorithm to use for minimizing the DFA. Default is hopcroft, but polynomial is allowed as well

Commands:
Poodle-Lex list-languages: Prints out a list of languages supportd by the -language option
Poodle-Lex list-minimizers: Prints out a list of DFA minimization algorithms supported by the --minimizer option.

Rules file:
The rules file is a simple format which describes the lexical analyzer as a 
set of token definitions, one on each line. The rules file consists of three
types of statements:
1) Token rules
2) Variable definitions
3) Token name reservations
4) Comments

Token rules take the following form:
[COMMAND] TOKEN_ID: PATTERN

Where TOKEN_ID is an alphanumeric ID, and PATTERN is a regular expression. 
PATTERN must be surrounded by either single or double quotes. Quotes can be 
escaped by using double-quotes ("" or '') inside of the pattern. If an "i" 
appears in front of the opening quote, then the pattern will be interpreted as 
case-insensitive for ASCII Latin characters.

PATTERN may consist of multiple strings, concatenated by "+". If a line ends 
with "+", then the expression may extend over multiple lines. If a piece of 
text matches two rules, then the rule appearing first is used.

COMMAND is an optional word which describes actions to be done with. Commands 
are case-insensitive, and valid commands are:
 - Skip: The pattern will be matched, but no token will be produced
 - Captured: The text of the match will be returned along with the token

Variable definitions take the following form:
Let VARIABLE_NAME = PATTERN

Variables can be substituted within a pattern, but are not themselves rules.
VARIABLE_NAME is the name of a variable to define. PATTERN is a pattern in the 
same format as with token rules.

Token name reservations take the following form:
Reserve TOKEN_ID

If used, this will add TOKEN_ID to the list of token ids. This can be used to 
reserve token ids, or create ids that can be emitted by a preprocessor.

Finally, any text on a line after "#" is considered a comment. 
 
Language plug-ins:
As packaged, Poodle-Lex supports the following language arguments
 - freebasic: FreeBasic language emitter with full Unicode support
 - c-ascii: C emitter using the stdio interface
 
The default language is freebasic. More languages can be supportd by 
installing plugins
 
Regular expression rules:
Poodle-Lex patterns use a regular expression syntax similar to the IEEE POSIX 
ERE standard. The pattern will match the characters present, and the following 
special characters can be used to define more complex patterns:
".": Matches any Unicode codepoint.
"[...]": Matches one of any characters inside of the brackets
"[^...]": Matches all Unicode codepoints except any characters inside the brackets.
"{m, n}": Matches the previous item if it repeats a minimum of m times and a maximum of n times.
"*": Matches the prevous item if it appears zero or more times in a row.
"+": Matches the previous item if it appears one or more times in a row.
"?": Matches the previous item if it appears zero or one times.
"(...)": Matches the patern within the parenthesis.
"{...}": Matches a pattern defined by a variable, identified by the text between the curly braces
"\": Matches a special character or the next character literally
"|": Matches either the previous item or the next item.

The following standard special characters are NOT accepted:
"$": In the POSIX ERE standard, matches text at the end of a line or input
"^": In the POSIX ERE standard, matches text at the start of a line or input

These symbols are not supported because they require additional context. The 
characters are not allowed except when escaped and they are reserved for 
future use.

The following special characters are supported:
"\t": Matches a tab (\x09) character
"\r": Matches a line feed (\x0a) character
"\n": Matches a carriage return (\x0d) characeter
"\x**": Matches a codepoint between 0 and 255, with "*" being any hexidecimal digit
"\u****": Matches a codepoint between 0 and 65535, with "*" being any hexidecimal digit
"\U******": Matches any Unicode codepoint, with "*" being any hexidecimal digit

The following named character classes are also supported within a character class:
"[:alnum:]" - Alphanumeric characters ([A-Za-z0-9])
"[:word:]" - Alphanumeric characters + "_" ([A-Za-z0-9_])
"[:alpha:]" - Alphabetical characters ([A-Za-z])
"[:blank:]" - Space and tab ([ \t])
"[:cntrl:]" - ASCII control characters ([\x01-\x1F])
"[:digit:]" - Numerical digits ([0-9])
"[:graph:]" - Visible characters ([\x21-\x7F])
"[:lower:]" - Lowercase characters ([a-z])
"[:print:]" - Printable characters ([\x20-\x7F])
"[:punct:]" - Punctuation ([\]\[\!\"\#\$\%\&\'\(\)\*\+\,\.\/\:\;\<\=\>\?\@\\\^\_\`\{\|\}\~\-])
"[:space:]" - Whitespace characters ([ \t\r\n\v\f])
"[:upper:]" - Uppercase characters ([A-Z])
"[:xdigit:]" - Hexadecimal digits ([A-Fa-f0-9])

Output:
When run, the program generates source code which provides an interface. The 
interface will take in a stream of text, and produce "tokens" in the form of
a structure. The structure will contain an enumerated identifier, and 
optionally a string containing the text which was grouped into the token.

Example:
The following generates, compiles, and executes a simple FreeBasic test 
application on Linux and Windows. Python 2.7 and FreeBASIC >= 0.90.1 should be 
installed prior to running. 

Windows:
1) Add the Poodle-Lex installation directory to your PATH environment variable
2) Copy any .rules files in the "Example" folder from the installation directory to any folder
3) Navigate to that folder in the command prompt
4) Enter the following, replacing RULES_FILE with the name of the rules file being used:
mkdir Output
Poodle-Lex RULES_FILE Output
cd Output\Demo
make_demo
Demo

Linux:
1) Sync the source
2) Install python 2.7
3) install blist (Ubuntu: sudo apt-get install python-blist)
4) Navigate to the source directory
4) Enter the following, replacing RULES_FILE with the nae of the rules file being used:
mkdir Output
python __main__.py RULES_FILE Output
cd Output/Demo
./make_demo.sh
./Demo

Credits:
Parker Michaels - Primary developer
AGS - C lexer example, countless bug reports and tests

Thank you to everyone who helped test or provided feedback for this tool. This 
includes members of the FreeBasic.net forum such as TFS.
